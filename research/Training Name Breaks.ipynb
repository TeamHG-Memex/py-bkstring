{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook will help to provide some documentation and reproducibility to training a username splitter.\n",
    "\n",
    "All necessary files are in the py-bkstring repo on the \"research\" branch.\n",
    "\n",
    "## Dependencies\n",
    "You will need to install the following python library:\n",
    "* [sklearn-crfsuite](https://github.com/TeamHG-Memex/sklearn-crfsuite)\n",
    "\n",
    "## Problem\n",
    "The main problem with reference to username matching, is that usernames are often made up of one or more words.  The main problem is that these words are not always separated by any discernible delimeter.\n",
    "\n",
    "## Suggested Solution\n",
    "In order to split names effectively, we will train a model to recognize where usernames should be broken apart.  The break points will be determined by character, so we know at the very least we should be gathering features based on each character within the \n",
    "\n",
    "To do this we will:\n",
    "\n",
    "1. Import all the things!\n",
    "1. Clean the dataset\n",
    "1. Process features\n",
    "1. Make the training set\n",
    "1. Train the model\n",
    "1. Show the results\n",
    "\n",
    "## Import all the things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the dataset\n",
    "Our dataset comes from a list of matching names from the \"data/name-matches.txt\" file, which takes the format:\n",
    "\n",
    "```\n",
    "=========================\n",
    "<name1>\n",
    "<name2>\n",
    "<name3>\n",
    "=========================\n",
    "<nameA>\n",
    "...\n",
    "```\n",
    "\n",
    "Where all names within the equals marks are a matching set.  This isn't particularly useful for name splitting, so we'll just create a list which will have the username, and the index of all spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('kalsen 2013', [6])\n"
     ]
    }
   ],
   "source": [
    "def names():\n",
    "    with open('data/name-matches.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    data = data.split('\\n=====================================\\n')\n",
    "\n",
    "    ret = list()\n",
    "    for line in data:\n",
    "        for name in line.split('\\n'):\n",
    "            if ' ' not in name:\n",
    "                continue\n",
    "\n",
    "            regex = [m.start() for m in re.finditer('\\s', name)]\n",
    "            ret.append((name, regex))\n",
    "\n",
    "    return ret\n",
    "\n",
    "# Take a look at the first name in the list as well as the whitespace index for that name.\n",
    "print(names()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: 'kalsen 2013' is the username, and there is a space at index of 6._\n",
    "\n",
    "## Process features\n",
    "We now need to figure out our mechanism to retrieve features from a character at a position in a given username.  A good starting point would be tracking the following data from each character:\n",
    "\n",
    "* lower (Character)\n",
    "* isupper (Boolean)\n",
    "* isdigit (Boolean)\n",
    "* islower (Boolean)\n",
    "* isalpha (Boolean)\n",
    "* position (Number)\n",
    "\n",
    "It is also helpful to know the same information about characters 1-3 positions ahead of and behind each given character.  This allows us train patterns of nearby characters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"+2:isupper\": false,\n",
      "  \"+3:isdigit\": false,\n",
      "  \"+3:position\": 4,\n",
      "  \"+3:isupper\": false,\n",
      "  \"+2:isdigit\": false,\n",
      "  \"-1:position\": 0,\n",
      "  \"+2:lower\": \"n\",\n",
      "  \"+1:position\": 2,\n",
      "  \"position\": 1,\n",
      "  \"isdigit\": false,\n",
      "  \"+3:lower\": \"d\",\n",
      "  \"isupper\": false,\n",
      "  \"+1:isalpha\": true,\n",
      "  \"+1:lower\": \"h\",\n",
      "  \"-1:lower\": \"j\",\n",
      "  \"length\": 8,\n",
      "  \"-1:isdigit\": false,\n",
      "  \"-1:isalpha\": true,\n",
      "  \"+2:isalpha\": true,\n",
      "  \"isalpha\": true,\n",
      "  \"islower\": true,\n",
      "  \"+1:islower\": true,\n",
      "  \"+2:islower\": true,\n",
      "  \"-1:isupper\": false,\n",
      "  \"-1:islower\": true,\n",
      "  \"+1:isdigit\": false,\n",
      "  \"+1:isupper\": false,\n",
      "  \"lower\": \"o\",\n",
      "  \"+3:isalpha\": true,\n",
      "  \"+3:islower\": true,\n",
      "  \"+2:position\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This function has a lot of redundant code and will be cleaned up in actual implementation.\n",
    "def features(name, i, flag=None):\n",
    "    char = name[i]\n",
    "\n",
    "    features = {\n",
    "        'lower': char.lower(),\n",
    "        'isupper': char.isupper(),\n",
    "        'isdigit': char.isdigit(),\n",
    "        'islower': char.islower(),\n",
    "        'isalpha': char.isalpha(),\n",
    "        'position': i,\n",
    "        'length': len(name)\n",
    "    }\n",
    "\n",
    "    if i == 0:\n",
    "        features['BON'] = True\n",
    "    else:\n",
    "        char = name[i - 1]\n",
    "        features.update({\n",
    "            '-1:lower': char.lower(),\n",
    "            '-1:isupper': char.isupper(),\n",
    "            '-1:isdigit': char.isdigit(),\n",
    "            '-1:islower': char.islower(),\n",
    "            '-1:isalpha': char.isalpha(),\n",
    "            '-1:position': i - 1\n",
    "        })\n",
    "\n",
    "    if i > 1:\n",
    "        char = name[i - 2]\n",
    "        features.update({\n",
    "            '-2:lower': char.lower(),\n",
    "            '-2:isupper': char.isupper(),\n",
    "            '-2:isdigit': char.isdigit(),\n",
    "            '-2:islower': char.islower(),\n",
    "            '-2:isalpha': char.isalpha(),\n",
    "            '-2:position': i - 2\n",
    "        })\n",
    "\n",
    "    if i > 2:\n",
    "        char = name[i - 3]\n",
    "        features.update({\n",
    "            '-3:lower': char.lower(),\n",
    "            '-3:isupper': char.isupper(),\n",
    "            '-3:isdigit': char.isdigit(),\n",
    "            '-3:islower': char.islower(),\n",
    "            '-3:isalpha': char.isalpha(),\n",
    "            '-3:position': i - 3\n",
    "        })\n",
    "\n",
    "    if i == len(name) - 1:\n",
    "        features['EON'] = True\n",
    "    else:\n",
    "        char = name[i + 1]\n",
    "        features.update({\n",
    "            '+1:lower': char.lower(),\n",
    "            '+1:isupper': char.isupper(),\n",
    "            '+1:isdigit': char.isdigit(),\n",
    "            '+1:islower': char.islower(),\n",
    "            '+1:isalpha': char.isalpha(),\n",
    "            '+1:position': i + 1\n",
    "        })\n",
    "\n",
    "    if i < len(name) - 2:\n",
    "        char = name[i + 2]\n",
    "        features.update({\n",
    "            '+2:lower': char.lower(),\n",
    "            '+2:isupper': char.isupper(),\n",
    "            '+2:isdigit': char.isdigit(),\n",
    "            '+2:islower': char.islower(),\n",
    "            '+2:isalpha': char.isalpha(),\n",
    "            '+2:position': i + 2\n",
    "        })\n",
    "\n",
    "    if i < len(name) - 3:\n",
    "        char = name[i + 3]\n",
    "        features.update({\n",
    "            '+3:lower': char.lower(),\n",
    "            '+3:isupper': char.isupper(),\n",
    "            '+3:isdigit': char.isdigit(),\n",
    "            '+3:islower': char.islower(),\n",
    "            '+3:isalpha': char.isalpha(),\n",
    "            '+3:position': i + 3\n",
    "        })\n",
    "\n",
    "    return features\n",
    "\n",
    "# Let's take a look at the feature dictionary!\n",
    "print(json.dumps(features('johndoe1', 1), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the training set\n",
    "We will need a set of features for a bunch of names, as well as set of whether there should be a breakpoint after the given character.  Our training data will be created by processing usernames with spaces, and putting a marker where the spaces exist, and then taking the spaces out before handing it over to the modeller.\n",
    "\n",
    "Example:\n",
    "```\n",
    "original_name = 'john doe'\n",
    "training_name = 'johndoe'\n",
    "spaces = [ 4 ]\n",
    "\n",
    "```\n",
    "\n",
    "At `name[0]` through `name[2]`, and `name[4]` through `name[6]` we will label as 'no_split_next,' and on `name[3]` we will label as 'yes_split_next.'\n",
    "\n",
    "This allows us to attempt to find breakpoints in names, with a pretty solid grounding truth of actually containing a space.  But the training set will have to work extra hard to try to find likely breakpoints in a username without being given an easy and obvious delimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j no_split_next\n",
      "o no_split_next\n",
      "h no_split_next\n",
      "n yes_split_next\n",
      "d no_split_next\n",
      "o no_split_next\n",
      "e no_split_next\n"
     ]
    }
   ],
   "source": [
    "def name_features(word, spaces):\n",
    "    word = word.replace(' ', '')\n",
    "    flag = None\n",
    "    feature_list = list()\n",
    "    split_list = list()\n",
    "\n",
    "    i_spacer = 1\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        split_flag = 'no_split_next'\n",
    "\n",
    "        if i + i_spacer in spaces:\n",
    "            split_flag = 'yes_split_next'\n",
    "            i_spacer += 1\n",
    "\n",
    "        feature_list.append(features(word, i, flag=flag))\n",
    "        split_list.append(split_flag)\n",
    "\n",
    "    return (feature_list, split_list)\n",
    "\n",
    "# This is just to show what labels look like for each letter in the username.\n",
    "feat, split = name_features('john doe', list([4]))\n",
    "for i in range(len(feat)):\n",
    "    print(feat[i]['lower'], split[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we'll actually create the training/testing sets.\n",
    "features = [name_features(name, spaces) for name, spaces in names()]\n",
    "\n",
    "X_train = list()\n",
    "Y_train = list()\n",
    "\n",
    "train_range = range(0, 2500)\n",
    "for i in train_range:\n",
    "    x, y = features[i]\n",
    "    X_train.append(x)\n",
    "    Y_train.append(y)\n",
    "\n",
    "test_range = range(2500, 3000)\n",
    "\n",
    "X_test = list()\n",
    "Y_test = list()\n",
    "\n",
    "for i in test_range:\n",
    "    x, y = features[i]\n",
    "    X_test.append(x)\n",
    "    Y_test.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "This sounds super interesting, but it's fairly simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the results\n",
    "We'll now take a look at our F1 score, though really we're very interested in precision here, and not terribly worried about recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "yes_split_next      0.803     0.687     0.740       550\n",
      "no_split_next      0.964     0.980     0.972      4653\n",
      "\n",
      "avg / total      0.947     0.949     0.947      5203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(Y_test, y_pred, labels=sorted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precision of .80 is really good, considering words in usernames don't have to follow any reason, including normal grammar, spelling, or naming conventions.  We could probably get a higher precision if we had more sources of usernames, and potentially attempt to fit against regular text with spaces in it.\n",
    "\n",
    "We could also try adding features to slide windows of characters near the current position.  Windows could consist of 2-4 character substrings, and go from -3 to +3.\n",
    "\n",
    "# Conclusion\n",
    "This seems like a pretty good way to attempt to split usernames for matching, but we can iterate and attempt to break at other markers other than spaces too.  One concern is that the training data only matches well against the given username set, so we may need to retrain every once in a while when the precision has dropped too low upon adding other usernames.\n",
    "\n",
    "In the end it's worth attempting to implement, and seeing if it improves our name matching overall.\n",
    "\n",
    "# Thank You\n",
    "A big thank you to [kmike](https://github.com/kmike), a lot of this notebook used examples from the [CoNLL2002 Notebook](https://github.com/TeamHG-Memex/sklearn-crfsuite/blob/master/docs/CoNLL2002.ipynb) from [sklearn-crfsuite](https://github.com/TeamHG-Memex/sklearn-crfsuite)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
